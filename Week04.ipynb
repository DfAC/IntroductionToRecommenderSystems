{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "#import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content Based Recommender - Lectures\n",
    "\n",
    "Content based recommender work best when there is a lot of new items which are difficult to be rated independently and we use similarities between objects instead. Basic idea is to find similarities between items and then based our recommendations on identified characteristics. This concept is based on build profile of attributes you find interesting.\n",
    "\n",
    "\n",
    "Just to clarify the defintions we are going to use\n",
    "\n",
    "### Content\n",
    "\n",
    "* set of description describing products\n",
    "* useful in recommendations\n",
    "\n",
    "### TFIDF\n",
    "\n",
    "* forward reference using vector references\n",
    "* define relevant terms\n",
    "* \\# docs / # docs with term\n",
    "\n",
    "\n",
    "## Content based filtering profile\n",
    "\n",
    "\n",
    "* build vector of attributes (keywords)\n",
    "* each attributes is a [dimension we are going to move along](https://en.wikipedia.org/wiki/Vector_space_model)\n",
    "  * more keywords, more dimensions\n",
    "* in this space we will define both the users and the items\n",
    "* we can find their preferences by finding object close in this space\n",
    "* we can ask users to create it directly\n",
    "  * difficult for users as we don't know our preferences\n",
    "* we wont use other ppl preferences to build your own (even if familiar)\n",
    "* in this model we understand that items liked are important. We cant separate those two.\n",
    "* system will be based on the search engine (index)\n",
    "* entree style recommending - as there was always option, users tended to explore a lot\n",
    "\n",
    "\n",
    "## Case based recommendations (K-space reasoning)\n",
    "\n",
    "* have database around set of relevant attributes\n",
    "* query based on example query and retrieve relevant cases \n",
    "* based on classical problem solving approach (DARPA)\n",
    "  * detecting problems as cases\n",
    "  * finding similarities between cases\n",
    "  * leading to case based maintenances\n",
    "  * this then lead to recommended systems \n",
    "  * important part is feedback (critique)\n",
    "  * review as case generation\n",
    "    * detect sentiment as well\n",
    "    * described products as cases\n",
    "    * solve problems using past problems experiences\n",
    "    * adoptation is important here\n",
    "* how to get latest information on the market\n",
    "  * [conference](http://www.iccbr.org/iccbr14/)\n",
    "  * [recsys](http://recsys.acm.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Personalized Recommenders\n",
    "\n",
    "\n",
    "## Read File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LKB\\Anaconda\\lib\\site-packages\\matplotlib\\__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy\n",
    "import copy\n",
    "\n",
    "#import pdb #debuggera\n",
    "%matplotlib inline\n",
    "\n",
    "from __future__ import division #so I can have float as std and int as //"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading Assignment2.csv\n",
      "reading Assignment2Users.csv\n"
     ]
    }
   ],
   "source": [
    "dataFile = \"Assignment2.csv\"\n",
    "print(\"reading %s\" % dataFile)\n",
    "dfData = pd.read_csv(dataFile, delimiter = \"\\t\", error_bad_lines=True, encoding = 'utf-8-sig',na_values = [\"NULL\",\"\"],header =0);\n",
    "\n",
    "dataFile = \"Assignment2Users.csv\"\n",
    "print(\"reading %s\" % dataFile)\n",
    "dfUsers = pd.read_csv(dataFile, delimiter = \"\\t\", error_bad_lines=True, encoding = 'utf-8-sig',na_values = [\"NULL\",\"\"],header =0);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "## Building simple user profile\n",
    "\n",
    "Build a very simple profile of user preferences for attributes. In this profile, you’ll count the total the number of positive and negative evaluations associated with each attribute, and create a profile with the total score for each attribute for each user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user1= dfUsers.iloc[:,0]\n",
    "user2= dfUsers.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def userProfile(preferecesData,userVotes):\n",
    "  cols = [pd.DataFrame(preferecesData[col].values * userVotes.values, columns=[col]) for col in preferecesData]\n",
    "  votes = cols[0].join(cols[1:])\n",
    "  votes = votes.sum()\n",
    "\n",
    "  return votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user1Profile = userProfile(dfData,user1)\n",
    "user2Profile = userProfile(dfData,user2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "baseball    -1.024564\n",
       "economics    1.000000\n",
       "politics     1.052786\n",
       "Europe       1.500000\n",
       "Asia        -0.447214\n",
       "soccer      -1.024564\n",
       "war         -0.077350\n",
       "security     1.500000\n",
       "shopping     0.000000\n",
       "family      -0.447214\n",
       "dtype: float64"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfData\n",
    "user2Profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying user profiles\n",
    "\n",
    "* Which document does the simple profile predict user 1 will like best?\n",
    "* What score does that prediction get?\n",
    "* How many documents does the model predict U2 will dislike (prediction score that is negative)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 1 fav doc is doc16 with score of 3.33.\n",
      "User 2 will dislike 4 docs.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "doc16    3.333585\n",
       "doc12    2.309021\n",
       "doc1     2.256235\n",
       "dtype: float64"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user1Preferences = userProfile(dfData.transpose(),user1Profile)\n",
    "user2Preferences = userProfile(dfData.transpose(),user2Profile)\n",
    "\n",
    "#user1Preferences.sort_values(inplace=True, ascending=False)\n",
    "\n",
    "print \"User 1 fav doc is {0} with score of {1:.2f}.\" .format(user1Preferences.idxmax(),user1Preferences.max())\n",
    "print \"User 2 will dislike {0} docs.\" .format(user2Preferences.iloc[user2Preferences.values<0].count())\n",
    "\n",
    "user1Preferences.sort_values(inplace=True,ascending=False)\n",
    "user1Preferences.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "## Building weighted user profile\n",
    "\n",
    "We want to explore whether our simple model may be counting these attribute-heavy documents too much. To try this out, make a copy of the attributes matrix on another sheet. Then we’re going to have you normalize each row to be a unit length vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docWeight = np.sqrt(dfData.sum(axis=1)) #weight based on no of items\n",
    "dfDataWeigthed= (dfData.transpose()/docWeight).transpose() #weigthed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying user profiles\n",
    "\n",
    "* Which document is now in second with this new model for user 1?\n",
    "* What prediction score does it have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user1Profile = userProfile(dfDataWeigthed,user1)\n",
    "user2Profile = userProfile(dfDataWeigthed,user2)\n",
    "\n",
    "user1Preferences = userProfile(dfDataWeigthed.transpose(),user1Profile)\n",
    "user2Preferences = userProfile(dfDataWeigthed.transpose(),user2Profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc16    1.924646\n",
      "doc6     1.370923\n",
      "doc12    1.333114\n",
      "dtype: float64\n",
      "User 1 fav doc is doc16 with score of 1.92.\n"
     ]
    }
   ],
   "source": [
    "user1Preferences.sort_values(inplace=True,ascending=False)\n",
    "print user1Preferences.head(3)\n",
    "\n",
    "print \"User 1 fav doc is {0} with score of {1:.2f}.\" .format(user1Preferences.idxmax(), user1Preferences.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3\n",
    "##  how common different terms are among our documents …\n",
    "\n",
    "We’re going to include an IDF (inverse document frequency) term into our equation. Start with your spreadsheet from part 2. Add a row that shows 1/DF where DF is the number of documents in which each content attribute occurs. For example, baseball occurs in 4 documents, so baseball’s entry will be 0.25. Politics occurs in 10 documents, so it will get an IDF score of 0.1 (1 / 10).\n",
    "\n",
    "Note that this is far more dramatic a computation than is usually used with large datasets (more common is 1 / log(DF)), but we need a dramatic value to see differences with a small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "baseball     0.250000\n",
       "economics    0.166667\n",
       "politics     0.100000\n",
       "Europe       0.090909\n",
       "Asia         0.166667\n",
       "soccer       0.166667\n",
       "war          0.142857\n",
       "security     0.166667\n",
       "shopping     0.142857\n",
       "family       0.200000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IDF = 1/dfData.sum(axis=0) #weight based on no of times term has been mentioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def userProfileWithIDF(preferecesData,userVotes,IDF):\n",
    "  cols = [pd.DataFrame(preferecesData[col].values * userVotes.values, columns=[col]) for col in preferecesData]\n",
    "  votes = cols[0].join(cols[1:])\n",
    "  votes = votes.sum()\n",
    "  votes = votes*IDF\n",
    "\n",
    "  return votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user1Profile = userProfileWithIDF(dfDataWeigthed,user1,IDF)\n",
    "user2Profile = userProfile(dfDataWeigthed,user2)\n",
    "\n",
    "user1PreferencesType3= userProfile(dfDataWeigthed.transpose(),user1Profile)\n",
    "user2PreferencesType3 = userProfile(dfDataWeigthed.transpose(),user1Profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "* Compare doc1 and doc9 for user1. What’s user1’s prediction for doc9 in the new IDF weighted model? See how there’s a dramatic difference from the prior model?\n",
    "* Now let’s look at user 2. Look at doc6. It was moderately positive before and now is slightly negative. Why did that change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Approach2</th>\n",
       "      <th>Approach3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doc9</th>\n",
       "      <td>1.132724</td>\n",
       "      <td>0.179067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc8</th>\n",
       "      <td>-0.370053</td>\n",
       "      <td>-0.047530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc7</th>\n",
       "      <td>-0.353553</td>\n",
       "      <td>-0.058926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc6</th>\n",
       "      <td>1.370923</td>\n",
       "      <td>0.319432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Approach2  Approach3\n",
       "doc9   1.132724   0.179067\n",
       "doc8  -0.370053  -0.047530\n",
       "doc7  -0.353553  -0.058926\n",
       "doc6   1.370923   0.319432"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d={'Approach2': user1Preferences, 'Approach3':user1PreferencesType3}\n",
    "compareResults = pd.DataFrame(data=d)\n",
    "compareResults.sort_index(inplace=True, ascending=False)\n",
    "compareResults.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Look at doc6. It was moderately positive before and now is slightly negative. It has two attributes, a common one the user really likes (Europe) and a rare one the user dislikes (Baseball). In prior models, the fact that the user liked Europe more than s/he disliked baseball was decisive, but this model recognizes that Baseball is rarer than Europe, and therefore should have more weight (after all, there are plenty of other articles about Europe)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
